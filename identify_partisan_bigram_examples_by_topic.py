'''
    identify_partisan_bigram_examples_by_topic.py
    
    > Reads in probabilities and standard errors for the 1000 most Republican/Democrat-leaning bigrams in speeches that 
    do and do not evoke God (generated by "estimate_partisan_bigram_probs_using_dummies.do") and calculates confidence
    intervals
    
    > For both Republicans and Democrats, identifies examples of partisan bigrams that have a significantly higher 
    probability of being spoken when God has been evoked, and groups these into topics (for Figures 2 and 3 in the 
    paper)
    
    > Stores partisan bigram examples for both parties with associated probability data (probabilities and CIs in God /
    non-God speeeches) in "data/<rep/dem>_prob_data_by_topic.dta"

'''


import pandas as pd


## Read in partisan bigram probability data and calculate confidence intervals (CIs) ##

# read in Republican/Democrat probability data
rep_prob_data = pd.read_stata('data/rep_prob_data.dta')
dem_prob_data = pd.read_stata('data/dem_prob_data.dta')

# read in names of partisan bigrams
rep_partisan_bigrams = pd.read_pickle('data/rep_partisan_bigrams.pkl')
dem_partisan_bigrams = pd.read_pickle('data/dem_partisan_bigrams.pkl')

# for each rep partisan bigram, calculate CIs of the probability amongst god / no-god speeches and store in dataframe

data = []
for p, partisan_bigram in enumerate(rep_partisan_bigrams):
    
    nogod_mean = rep_prob_data.loc[0, f'm{partisan_bigram}']
    nogod_se = rep_prob_data.loc[0, f'se{partisan_bigram}']
    nogod_lb = nogod_mean - 1.96*nogod_se
    nogod_ub = nogod_mean + 1.96*nogod_se

    god_mean = rep_prob_data.loc[1, f'm{partisan_bigram}']
    god_se = rep_prob_data.loc[1, f'se{partisan_bigram}']
    god_lb = god_mean - 1.96*god_se
    god_ub = god_mean + 1.96*god_se
    
    partisan_bigram_data = [partisan_bigram,nogod_mean,nogod_se,nogod_lb,nogod_ub,
                   god_mean,god_se,god_lb,god_ub]
        
    data.append(partisan_bigram_data)
    
rep_prob_data_plus_CIs = pd.DataFrame(data, columns=['partisan_bigram','nogod_mean','nogod_se','nogod_lb','nogod_ub',
                                          'god_mean','god_se','god_lb','god_ub'])


# for each dem partisan bigram, calculate CIs of the probability amongst god / no-god speeches and store in dataframe

data = []
for p, partisan_bigram in enumerate(dem_partisan_bigrams):
    
    nogod_mean = dem_prob_data.loc[0, f'm{partisan_bigram}']
    nogod_se = dem_prob_data.loc[0, f'se{partisan_bigram}']
    nogod_lb = nogod_mean - 1.96*nogod_se
    nogod_ub = nogod_mean + 1.96*nogod_se

    god_mean = dem_prob_data.loc[1, f'm{partisan_bigram}']
    god_se = dem_prob_data.loc[1, f'se{partisan_bigram}']
    god_lb = god_mean - 1.96*god_se
    god_ub = god_mean + 1.96*god_se
    
    partisan_bigram_data = [partisan_bigram,nogod_mean,nogod_se,nogod_lb,nogod_ub,
                   god_mean,god_se,god_lb,god_ub]
        
    data.append(partisan_bigram_data)
    
dem_prob_data_plus_CIs = pd.DataFrame(data, columns=['partisan_bigram','nogod_mean','nogod_se','nogod_lb','nogod_ub',
                                          'god_mean','god_se','god_lb','god_ub'])


## Identify partisan bigrams examples where significantly higher probability of being spoken when God has been evoked ##

# such bigrams occur where probability lower bound in god speeches higher than upper bound in non-god speeches
rep_god_sig_higher = rep_prob_data_plus_CIs[rep_prob_data_plus_CIs.god_lb > rep_prob_data_plus_CIs.nogod_ub]
dem_god_sig_higher = dem_prob_data_plus_CIs[dem_prob_data_plus_CIs.god_lb > dem_prob_data_plus_CIs.nogod_ub]

# order these by the difference in magnitude in probability between the god and non-god speeches, and inspect in excel
rep_god_sig_higher['mean_diff'] = rep_god_sig_higher.god_mean - rep_god_sig_higher.nogod_mean 
dem_god_sig_higher['mean_diff'] = dem_god_sig_higher.god_mean - dem_god_sig_higher.nogod_mean 

rep_god_sig_higher = rep_god_sig_higher.sort_values(by='mean_diff',ascending=False)
dem_god_sig_higher = dem_god_sig_higher.sort_values(by='mean_diff',ascending=False)

rep_god_sig_higher.to_excel('data/rep_god_sig_higher.xlsx',index=False)
dem_god_sig_higher.to_excel('data/dem_god_sig_higher.xlsx',index=False)

# group Republican examples into topics ##
rep_examples_by_topic={}
rep_examples_by_topic['war_on_terror']=['war_terror','al_qaeda','terrorist_attack','bin_laden','radic_islam']
rep_examples_by_topic['defense']=['arm_forc','air_forc','nation_defens','ballist_missil','send_troop']
rep_examples_by_topic['immigration']=['illeg_immigr','border_patrol','secur_border','illeg_alien','control_border']
rep_examples_by_topic['role_of_state']=['big_govern','limit_govern','tax_relief','lower_tax','tax_burden'] 
rep_examples_by_topic['abortion'] = ['unborn_children','birth_abort','innoc_human','unborn_babi','innoc_unborn'] 
rep_examples_by_topic['communism'] = ['communist_parti','red_china','communist_regim','communist_china','communist_govern'] 
rep_examples_by_topic['narcotics'] = ['illeg_drug','drug_dealer','drug_use','drug_traffick','drug_smuggler'] 

# group Democrat examples into topics ##
dem_examples_by_topic = {}
dem_examples_by_topic['healthcare'] = ['health_care','medic_care','public_health','care_cost','care_reform']
dem_examples_by_topic['welfare'] = ['social_secur','minimum_wage','poor_peopl','lose_job','safeti_net']
dem_examples_by_topic['education']=['public_school','educ_opportun','educ_program','public_educ','student_loan']
dem_examples_by_topic['civil_rights']=['african_american','constitut_right','equal_opportun','vote_right','equal_right']
dem_examples_by_topic['environment']=['natur_resourc','natur_disast','clean_air','environment_protect','climat_chang']
dem_examples_by_topic['nuclear']=['nuclear_war','atom_energi','nuclear_test','nuclear_arm','nuclear_warhead']
dem_examples_by_topic['gun_control']=['arm_control','assault_weapon','gun_control','gun_violenc','buy_gun']

# associate Republican partisan bigrams grouped by topic with probability data / CIs and save to .dta file
rep_prob_data_by_topic = pd.DataFrame()
for topic in rep_examples_by_topic.keys():
    data = rep_prob_data_plus_CIs[rep_prob_data_plus_CIs.partisan_bigram.isin(rep_examples_by_topic[topic])]
    data['topic'] = topic
    rep_prob_data_by_topic = pd.concat([rep_prob_data_by_topic, data]).reset_index(drop=True)

obj_type_cols = list(rep_prob_data_by_topic.select_dtypes(include=['object']).columns)
rep_prob_data_by_topic[obj_type_cols] = rep_prob_data_by_topic[obj_type_cols].astype(str)
rep_prob_data_by_topic.to_stata('data/rep_prob_data_by_topic.dta', write_index=False, version=117)

# associate Democrat partisan bigrams grouped by topic with probability data / CIs and save to .dta file
dem_prob_data_by_topic = pd.DataFrame()
for topic in dem_examples_by_topic.keys():
    data = dem_prob_data_plus_CIs[dem_prob_data_plus_CIs.partisan_bigram.isin(dem_examples_by_topic[topic])]
    data['topic'] = topic
    dem_prob_data_by_topic = pd.concat([dem_prob_data_by_topic, data]).reset_index(drop=True)

obj_type_cols = list(dem_prob_data_by_topic.select_dtypes(include=['object']).columns)
dem_prob_data_by_topic[obj_type_cols] = dem_prob_data_by_topic[obj_type_cols].astype(str)
dem_prob_data_by_topic.to_stata('data/dem_prob_data_by_topic.dta', write_index=False, version=117)


