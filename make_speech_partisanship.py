'''
    make_speech_partisanship.py
    
    > Reads in speech-level term frequencies generated by "make_term_frequencies.py" and the partisanship scores of 
    different congressional bigrams from Gentzkow et al. (2019)
    
    > Generates a partisanship score for each speech by summing the partisanship scores of its bigrams (see formula in 
    in section 3.3.1 of the paper)
    
    > Speech partisanship stored by year in "data/congress"                                                                                                  
    

'''

import time as tim
import pandas as pd

## Create mapping from Congressional session to year (as bigram partisanship scores are by session) ##

start_year = 1949
end_year = 2014
start_session = 81

congress_sessions = {}
session = start_session
for y in range(end_year-start_year+1):
    year = start_year+y
    
    congress_sessions[year] = session

    if y % 2:
        session = session+1


# Make speech partisanship ##

# read in corpus dictionary (gensim dictionary object)
dct = pd.read_pickle('data/dct.pkl')

start_year = 1950
end_year = 2014
t = tim.time()

for chamber in ['H','S']:
    for year in range(start_year, end_year+1):
    
        print(f'\n\nChamber: {chamber}. Year: {year}')
        
        # tracks running time
        secs = tim.time() - t
        days, secs = secs // 86400, secs % 86400
        hours, secs = secs // 3600, secs % 3600
        mins, secs = secs // 60, secs % 60 
        print(f'Elapsed time: {int(days)}d:{int(hours)}h:{int(mins):0>2}m:{int(secs):0>2}s')
    
        # read in term frequencies for the current year   
        year_tfs = pd.read_pickle(f'data/congress/{chamber}/{year}-tfs.pkl')
    
        # retrieve bigram partisanship scores from text file for the session that corresponds to the current year
        session = congress_sessions[year]        
        session_file = f'partisan_phrases_0{session}.txt' if session < 100 else f'partisan_phrases_{session}.txt'       
        with open(f'data/gentzkow/phrase_partisanship/{session_file}', 'r', encoding='utf-8') as f:
            partisan_bigram_rows = f.readlines()[1:]          
        partisan_bigram_scores  = {row[:row.index('|')].replace(' ', '_').strip(): float(row[row.index('|')+1:])  for row in partisan_bigram_rows}
        
        # drop bigrams that contain the word "god"
        partisan_bigram_scores = {bigram: score for bigram, score in partisan_bigram_scores.items() if 'god' not in bigram}
        
        # map bigram scores to bigram IDs in corpus dictionary
        partisan_bigram_id_scores = {dct.token2id[bigram]: score for bigram, score in partisan_bigram_scores.items()}
                             
        # create empty list to store speech-level partisanship scores for the current year
        year_partisan_scores = []
        
        for speech_tfs in year_tfs:
            
            # determine set of (highly-partisan) bigrams within speech (that have been given a partisanship score)
            speech_partisan_bigrams = {token_id for token_id, tf in speech_tfs if token_id in partisan_bigram_id_scores.keys()}           
            
            # sum to create speech partisanship measure (see Section 3.1.1)
            speech_partisan_score = sum([partisan_bigram_id_scores[token_id] for token_id in speech_partisan_bigrams])            
            
            year_partisan_scores.append(speech_partisan_score)
            
        pd.to_pickle(year_partisan_scores, f'data/congress/{chamber}/{year}-partisan_scores.pkl')


